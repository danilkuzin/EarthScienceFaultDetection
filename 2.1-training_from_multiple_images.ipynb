{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tqdm import trange\n",
    "\n",
    "from src.DataPreprocessor.data_preprocessor import DataPreprocessor, Mode\n",
    "from src.DataPreprocessor.DataIOBackend.gdal_backend import GdalBackend\n",
    "from src.DataPreprocessor.data_visualiser import DataVisualiser\n",
    "from src.LearningKeras.net_architecture import cnn_150x150x5,cnn_150x150x5_3class\n",
    "from src.LearningKeras.train import KerasTrainer\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data_visualisation for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:optical images are not match in 1-2 pixels in size\n",
      "WARNING:root:optical images are not match in 1-2 pixels in size\n"
     ]
    }
   ],
   "source": [
    "dataio_backend_1 = GdalBackend()\n",
    "dataio_backend_2 = GdalBackend()\n",
    "\n",
    "data_preprocessor_1 = DataPreprocessor(data_dir=\"data/Region 1 - Lopukangri/\",\n",
    "                              backend=dataio_backend_1,\n",
    "                              filename_prefix=\"tibet\",\n",
    "                              mode=Mode.TRAIN,\n",
    "                              seed=1)\n",
    "\n",
    "data_preprocessor_2 = DataPreprocessor(data_dir=\"data/Region 2 - Muga Puruo/\",\n",
    "                              backend=dataio_backend_2,\n",
    "                              filename_prefix=\"mpgr\",\n",
    "                              mode=Mode.TRAIN,\n",
    "                              seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_generator_1 = data_preprocessor_1.train_generator(batch_size=batch_size,\n",
    "                                         class_probabilities=np.array([1./3, 1./3, 1./3]),\n",
    "                                         patch_size=(150, 150),\n",
    "                                         channels=np.array([0, 1, 2, 3, 4]))\n",
    "\n",
    "train_generator_2 = data_preprocessor_2.train_generator(batch_size=batch_size,\n",
    "                                         class_probabilities=np.array([1./3, 1./3, 1./3]),\n",
    "                                         patch_size=(150, 150),\n",
    "                                         channels=np.array([0, 1, 2, 3, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import threading\n",
    "\n",
    "#lock = threading.Lock()\n",
    "def joint_generator():\n",
    "    while True:\n",
    "            img_batch_1, lbl_batch_1 = next(train_generator_1)\n",
    "            img_batch_2, lbl_batch_2 = next(train_generator_2)\n",
    "            img_joint = np.concatenate((img_batch_1, img_batch_1), axis=0)\n",
    "            lbl_joint = np.concatenate((lbl_batch_1, lbl_batch_2), axis=0)\n",
    "            #with lock:\n",
    "            yield img_batch_1, lbl_batch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator = lambda: cnn_150x150x5_3class()\n",
    "ensemble_size = 2\n",
    "batch_size = 5\n",
    "\n",
    "trainer = KerasTrainer(model_generator=model_generator,\n",
    "                       ensemble_size=ensemble_size,\n",
    "                       data_preprocessor=None,\n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 1/50 [..............................] - ETA: 20:56 - loss: 1.1045 - acc: 0.5000"
     ]
    }
   ],
   "source": [
    "\n",
    "#generator = joint_generator()\n",
    "\n",
    "history_arr = trainer.train(steps_per_epoch=50, epochs=5, train_generator=joint_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ensemble_size):\n",
    "    pathlib.Path('models_joint').mkdir(parents=True, exist_ok=True)\n",
    "    trainer.models[i].save_weights('models_joint/model_{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
